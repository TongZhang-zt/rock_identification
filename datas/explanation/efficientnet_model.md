
<div align="center">

# EfficientNet Model

</div>

## 什么是EfficientNet？

<p style="text-indent: 2em;">
EfficientNet是Google Research在2019年提出的一系列卷积神经网络模型（<a href="https://ar5iv.labs.arxiv.org/html/1905.11946?_immersive_translate_auto_translate=1">论文：EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a>）。它的核心目标是在计算资源受限（如移动设备、嵌入式设备）或大规模部署（如云端大量推理请求）的场景下，最大化模型的精度，同时最小化模型的参数量和计算量。
</p>

<p style="text-indent: 2em;">
简单来说，EfficientNet致力于用最小的代价（计算资源、时间、能耗）换取最高的模型性能（准确率）。
</p>

## 卷积神经网络
<p style="text-indent: 2em;">
卷积神经网络（Convolutional Neural NetWork,CNN）是一种在计算机视觉领域取得成功的深度学习模型。它由卷积层、池化层、激活函数和全连接层组成，可以对输入的图像进行特征提取、分类和回归。其设计灵感是模仿人类视觉系统的工作原理，通过对图像的局部区域进行特征提取，并将这些特征组合成全局表示。
</p>

### 图像原理
<p style="text-indent: 2em;">
在计算机视觉领域，图像是由像素组成的二维矩阵。图像的每个像素都可以看作是一个数值，代表图像的强度或亮度。大多数图像的表达方式是RGB颜色模型，即红绿蓝三原色的混合。在RGB模型中，每个像素的颜色由红、绿、蓝三个分量组成，每个分量的取值范围是0~255。我们可以将其看做是三维空间中的一个点，这个点的坐标为(x,y,z)，其中x、y分别表示图像的宽度和高度，z表示颜色的强度。
</p>

![](/rock_identification/datas/image/image_rgb.png)

### 传统神经网络与卷积神经网络
<p style="text-indent: 2em;">
传统的神经网络模型是基于人工神经元的网络模型，它由输入层、隐藏层和输出层组成。输入层接受外部输入，经过一系列的处理，最终输出结果。隐藏层是由神经元组成的网络，它接受输入信号，对其进行加工处理，并输出新的信号。输出层则是对隐藏层的输出进行处理，输出最终的结果。
</p>

![](/rock_identification/datas/image/Neural_Network.jpg)

<p style="text-indent: 2em;">
卷积神经网络（CNN）等深度学习模型在卷积层中引入了卷积操作，它可以提取图像的局部特征而不受位置的影响。在传统的神经网络模型中，输入信号经过一系列的神经元，最后输出结果。而在卷积神经网络模型中，输入信号经过一系列的卷积层，在卷积层中，卷积操作可以提取图像的局部特征。卷积层的输出信号经过一系列的非线性激活函数，如ReLU、Sigmoid等，最后输出结果。
</p>

### 什么是卷积？
<p style="text-indent: 2em;">
卷积是指对两个函数做卷积运算，即求两个函数在某一点的乘积，并将结果和原函数在该点的位置进行叠加。在图像处理中，卷积可以用来提取图像的局部特征。
</p>
下面是一个简单的卷积示例：

输入矩阵 (3x3)：

| 1 | 2 | 3 |

| 4 | 5 | 6 |

| 7 | 8 | 9 |

卷积核 (2x2)：

| -1 | 0 |

| 0  | 1 |

**步骤 1**：左上角区域
| 1 | 2 |
| 4 | 5 |
计算：`(1×-1) + (2×0) + (4×0) + (5×1) = 4`

**步骤 2**：右上角区域
| 2 | 3 |
| 5 | 6 |
计算：`(2×-1) + (3×0) + (5×0) + (6×1) = 4`

输出特征图 (2x2)：

| 4 | 4 |

| 4 | 4 |

![](/rock_identification/datas/image/convolution_demo.gif)

### 什么是池化？
<p style="text-indent: 2em;">
池化是指对输入矩阵进行降采样，即将原矩阵的分辨率降低，得到一个新的矩阵。池化可以用来降低模型的计算量和参数量，并提取图像的全局特征。
</p>
<p style="text-indent: 2em;">
池化的操作有最大池化和平均池化两种。最大池化是指取池化窗口内的最大值，平均池化是指取池化窗口内的平均值。
</p>
下面是一个池化示例：

输入矩阵 (4x4)：

| 1 | 2 | 3 | 4 |

| 5 | 6 | 7 | 8 |

| 9 | 10 | 11 | 12 |

| 13 | 14 | 15 | 16 |

池化窗口大小为 2x2，步长为 2：

**步骤 1**：取窗口 (1,1) ~ (2,2)

| 1 | 2 |
| 5 | 6 |

计算：`max(1, 2, 5, 6) = 6`

**步骤 2**：取窗口 (2,2) ~ (4,4)

| 7 | 8 |
| 11 | 12 |

计算：`max(7, 8, 11, 12) = 12`

输出矩阵 (2x2)：

| 6 | 12 |

| 12 | 16 |

![](/rock_identification/datas/image/max_pooling_demo.gif)

##### 池化的主要目的

**1. 降维和减少计算量：** 
减少特征图的空间尺寸（宽度和高度），显著降低后续层的参数数量和计算复杂度。
**2. 提取主要特征：** 
保留最显著的特征（如最大池化），提高特征的空间不变性（对微小位移、旋转不敏感）。
**3. 防止过拟合：** 
通过减少参数数量降低模型复杂度，提高模型的泛化能力。
**4. 扩大感受野：** 
使后续层能看到更广的原始输入区域。

### 什么是激活函数？
<p style="text-indent: 2em;">
激活函数是指对卷积层的输出进行非线性变换，以提高模型的非线性拟合能力。
</p>
<p style="text-indent: 2em;">
常见的激活函数有ReLU、Sigmoid、Tanh、LeakyReLU等。
</p>

### 什么是全连接层？
<p style="text-indent: 2em;">
全连接层（Fully Connected Layer）是指将卷积层的输出变换为一维向量，再输入到全连接层中，进行分类或回归。
</p>
<p style="text-indent: 2em;">
全连接层的作用是将卷积层提取到的特征进行整合，并进行分类或回归。
</p>

### 卷积神经网络的构造
<p style="text-indent: 2em;">
卷积神经网络由卷积层、池化层、激活函数和全连接层组成。
</p>
<p style="text-indent: 2em;">
卷积层：卷积层是卷积神经网络的核心，它提取图像的局部特征。卷积层由多个卷积层组成，每个卷积层包含多个卷积核，每个卷积核与输入图像的局部区域进行卷积运算，提取图像的特征。
</p>
<p style="text-indent: 2em;">
池化层：池化层是卷积神经网络的辅助层，它对卷积层的输出进行降采样，降低模型的计算量和参数量，提取图像的全局特征。池化层的主要目的是降低模型的计算量和参数量，并提取图像的全局特征。
</p>
<p style="text-indent: 2em;">
激活函数：激活函数是卷积神经网络的辅助层，它对卷积层的输出进行非线性变换，提高模型的非线性拟合能力。
</p>
<p style="text-indent: 2em;">
全连接层：全连接层是卷积神经网络的输出层，它将卷积层的输出变换为一维向量，再输入到全连接层中，进行分类或回归。
</p>

![](/rock_identification/datas/image/neural.png)

## EfficientNet的结构
<p style="text-indent: 2em;">
EfficientNet是Google Research在2019年提出的一种卷积神经网络模型，它在结构上与ResNet、DenseNet、Inception等模型有所不同。EfficientNet的核心思想是通过精心设计网络架构，在保证准确率的前提下，减少模型的计算量和参数量。
</p>

![模型大小与imagenet精度的关系](/rock_identification/datas/image/x1.png)

![模型缩放](/rock_identification/datas/image/x2.png)
(a)是基线网络示例；(b)-(d)是常规缩放，仅增加网络宽度、深度或分辨率的一个维度。(e)是我们提出的复合缩放方法，它以固定的比率均匀地缩放所有三个维度。

<p style="text-indent: 2em;">
EfficientNet的网络架构由多个模块组成，每个模块由多个卷积层、池化层、激活函数和全连接层组成。EfficientNet的网络架构如下图所示：
</p>

头和尾结构：
![](/rock_identification/datas/image/stem.png)

躯干结构：
![](/rock_identification/datas/image/module.png)

EfficientNet-B0：
![](/rock_identification/datas/image/efficientnet-b0.png)

EfficientNet-B1：
![](/rock_identification/datas/image/efficientnet-b1.png)

EfficientNet-B2：
B2与B1相同，唯一的区别是特征图(通道)的数量不同，增加了参数的数量。

EfficientNet-B3：
![](/rock_identification/datas/image/efficientnet-b3.png)

EfficientNet-B4：
![](/rock_identification/datas/image/efficientnet-b4.png)

EfficientNet-B5：
![](/rock_identification/datas/image/efficientnet-b5.png)

EfficientNet-B6：
![](/rock_identification/datas/image/efficientnet-b6.png)

EfficientNet-B7：
![](/rock_identification/datas/image/efficientnet-b7.png)

## EfficientNet_B4详细解读
<p style="text-indent: 2em;">
EfficientNet-B4是EfficientNet家族中的一个重要成员，代表了在模型精度、速度和大小之间取得优秀平衡的一种架构。
</p>

**核心思想：复合缩放：**
要理解efficientnet-b4的关键在于理解其背后的EfficientNet家族的核心创新：复合缩放。传统的模型通常只是单一地：
- **增加深度 (Depth)：** 添加更多的层（如从 ResNet-50 到 ResNet-101）。问题：梯度消失/爆炸，训练困难。
- **增加宽度 (Width)：** 增加每层的通道数（卷积核数量）。问题：更宽的浅层网络难以捕获高层次特征。
- **增加分辨率 (Resolution)：** 使用更高分辨率的输入图像。问题：计算量（FLOPs）呈平方级增长。

EfficientNet的作者通过系统的实验发现，单一的深度、宽度、分辨率的训练方式是不够的。因此，EfficientNet提出了一种新的方法：复合缩放。就是使用一个**符合系数φ**来同时调整深度、宽度、分辨率：

- **深度： d = α^φ**
- **宽度： w = β^φ**
- **分辨率： r = γ^φ**
- **约束： α * β² * γ² ≈ 2 且 α ≥ 1, β ≥ 1, γ ≥ 1**

其中:

- α, β, γ 是通过在较小的基线模型（EfficientNet-B0）上进行小型神经网络架构搜索（NAS）确定的常量，确定了三个维度之间最优的相对比例。论文中得出的近似最优值是 α=1.2, β=1.1, γ=1.15。
- φ 是一个用户指定的复合缩放系数，它决定了模型整体的大小和计算成本。φ 越大，模型越大、越精确、计算量也越大。

**EfficientNet-B4的定位：**

- 基线模型： EfficientNet-B0 (φ=0)。
- 缩放系数： EfficientNet-B4 对应 φ=1.6。
- 含义： 以基线模型 B0 为基础，应用复合缩放规则，将深度缩放约 1.2^1.6 ≈ 1.3 倍，宽度缩放约 1.1^1.6 ≈ 1.2 倍，分辨率缩放约 1.15^1.6 ≈ 1.3 倍（分辨率从 B0 的 224x224 增加到 B4 的 380x380）。

**核心网络架构：MBConv with SE**

尽管进行了缩放，所有 EfficientNet 模型（包括 B4）都共享相同的基础构建块，称为 MBConv Block，并加入了 Squeeze-and-Excitation (SE) 模块。

**1.MBConv(Mobile Inverted Residual Bottleneck Convolution):**

- 灵感来源： MobileNetV2 的 Inverted Residual Block。是一种轻量级的卷积块，其结构类似于 ResNet 的 Bottleneck Block。
- 结构： 
  - 扩展层 (1x1 Conv)： 首先使用 1x1 卷积 扩展 输入通道数（通常扩展 4 或 6 倍）。增加通道数让模型有更大的容量学习特征。
  - 深度可分离卷积 (Depthwise Conv)： 核心计算层。对每个输入通道使用一个单独的 3x3 或 5x5 卷积核进行卷积。大幅减少了参数数量和计算量 (FLOPs)。
  - SE 模块 (可选但常用)： 插入在深度卷积之后。
    - Squeeze:对每个通道进行全局平均池化（GAP），得到一个描述通道全局信息的向量。
    - Excitation： 通过一个小型全连接网络（通常包含一个降维层和一个升维层，中间有非线性激活如 ReLU/Swish）学习每个通道的重要性权重（一个 0 到 1 之间的值）。
    - Scale： 将学习到的权重乘以原始特征图的对应通道，实现通道维度的自适应特征重标定。让模型更关注信息量大的通道。
  - 投影层(1x1 Conv)： 最后使用 1x1 卷积 压缩 通道数，通常压缩回与输入通道数相同或略多（如果 stride>1）。这一步也去除了扩展层引入的部分冗余。
- 激活函数：主要使用Swish(x*sigmoid(x))激活函数,比ReLU在某些情况下更好。
- 残差连接：当输入和输出的张量形状（空间尺寸和通道数）匹配时，添加残差连接（输入直接加到投影层输出之后），有助于缓解梯度消失，使深层网络更容易训练。如果 stride>1 或通道数改变，则需要一个短的投影层（通常是 1x1 Conv）来调整输入形状。


> Squeeze-and-Excitation (SE) 模块中的三个核心操作：Squeeze、Excitation 和Scale。这个模块的核心思想是让网络学会自适应地校准通道（Channel）维度的特征响应，即让模型更关注那些信息量大的特征通道，抑制不那么重要的通道。
> 
> 想象一下，卷积层输出的特征图（Feature Map）是一个 [C, H, W] 的张量：
> - C： 通道数（Channel），每个通道可以看作是一个“特征探测器”（例如，一个通道可能专门检测“猫耳朵”，另一个通道检测“猫胡须”）。
> - H 和 W： 空间高度（Height）和宽度（Width），代表特征图在空间上的位置信息。
> 
> SE 模块作用于这个特征图的通道维度 C。它的目标是为每个通道计算一个权重值（0 到 1之间），这个权重值代表了该通道特征的重要性。然后，用这个权重去缩放（Scale） 对应通道的所有空间位置（H xW）上的激活值。重要的通道权重接近 1（被增强），不重要的通道权重接近 0（被抑制）。 现在分解三个步骤：
> 
>**1.Squeeze（挤压）：**
> - 目的： 获取每个通道的全局空间信息摘要。传统的卷积操作在空间上是局部的（感受野有限）。Squeeze 步骤试图捕获每个通道在整个特征图空间范围 (H x W) 上的全局分布信息。
> - 操作： 全局平均池化（Global Average Pooling, GAP）。这是最常用且最有效的方式。
>   - 对特征图的每一个通道 c（c=1, 2, ..., C） 单独操作。
>   - 将该通道 c 上所有 H x W 个空间位置的值求平均。
>   - 结果： 将一个 [C, H, W] 的特征图，压缩成一个 [C, 1, 1] 的向量（或者简单地看作一个长度为 C 的向量 z）。
>    - z = [z₁, z₂, ..., zc, ..., zC]，其中 zc = (1/(H*W)) * Σ(i=1 to H)Σ(j=1 to W) uc(i, j)。
>    - uc(i, j) 表示第 c 个通道在空间位置 (i, j) 的激活值。
> - 意义：向量 z 中的每个元素 zc 代表了第 c 个通道在整个空间上的平均激活强度。它是对该通道所检测特征的全局重要性的一个初步估计。数值大意味着该通道的特征在图像中普遍存在且显著；数值小则意味着该特征不显著或分布稀疏。
> 
> **2.Excitation（激活）：**
> - 目的： 学习每个通道的权重。基于 Squeeze 得到的全局信息 z，学习一个非线性的、通道间的依赖关系模型，为每个通道生成一个重要性权重（一个介于 0 到 1 之间的标量）。
> - 操作： 使用一个小型的两层全连接（Fully Connected, FC）神经网络（或称为瓶颈结构 Bottleneck）。
>   - 第一层 FC (降维层)：
>   - 输入：Squeeze 得到的向量 z (长度 C)。
>   - 操作：乘以一个权重矩阵 W1 (维度 [C/r, C])，其中 r 是一个缩减比率（Reduction Ratio） (例如，r=4 或 r=16)。
>   - 输出：一个长度更短的向量 (维度 C/r)。
>   - 激活函数：通常使用 ReLU，用于引入非线性。
>   - 作用： 降维，减少计算量并增强非线性建模能力。r 控制着模型的复杂度和容量。
>  - 第二层 FC (升维层)：
>    - 输入：第二层 FC 输出的向量 (维度 C/r)。
>    - 操作：乘以一个权重矩阵 W2 (维度 [C, C/r])。
>    - 输出：一个长度为 C 的向量，代表每个通道的重要性权重。
>    - 激活函数：通常使用 sigmoid，将输出限制在 0 到 1 之间。
>    - 作用： 升维，恢复到原来的维度。
> - 意义： 向量 s 中的每个元素 sc 就是学习到的第 c 个通道的重要性权重。这个权重不是固定规则设定的，而是网络根据当前输入的特征图，通过这个小型的神经网络自适应地学习出来的。它综合考虑了所有通道的全局信息（通过
> z），并建模了通道间的复杂依赖关系（通过 FC 层的非线性组合）。sc 越接近 1，表示网络认为第 c 个通道在当前上下文下越重要；越接近
> 0 表示越不重要。
> 
> **3.Scale（缩放）：**
> - 目的： 应用学习到的权重。将 Excitation 步骤计算出的通道权重 s 应用到原始输入特征图的对应通道上，实现特征通道的重校准（Recalibration）。
> - 操作： 通道级的乘法（Channel-wise Multiplication）。
>  - 对于原始输入特征图 U（维度 [C, H, W]）。
>  - 对于每一个通道 c：
>   - 取出该通道对应的权重 sc（一个标量）。
>   - 将该通道 c 的所有空间位置 (H x W) 上的激活值 uc(i, j) 乘以 sc。
>   - Ûc(i, j) = sc * uc(i, j)。
>  - 结果： 得到一个和原始特征图 U 维度相同（[C, H, W]）的新特征图 Û。
> - 意义： 这一步是 SE 模块的核心输出。它根据学习到的通道重要性 s，增强了那些对当前任务更相关的特征通道（sc 大的通道），减弱了那些相关性较低或噪声较多的通道（sc
> 小的通道）。这种调整是空间自适应的（对整个通道的所有空间位置同时缩放），也是数据自适应的（权重 s 是网络根据具体输入计算出来的）。
> 
> 总结 SE 模块的工作流程：
>  - Squeeze: 通过全局平均池化 (GAP) 将空间信息压缩成一个通道描述向量 z（每个元素代表一个通道的全局强度）。
>  - Excitation: 通过一个小型瓶颈神经网络（两层 FC + ReLU/Sigmoid）处理 z，学习出每个通道的重要性权重向量 s（0~1）。
>  - Scale: 将权重向量 s 按通道对应地乘回原始特征图，得到重校准后的特征图 Û（重要特征被加强，次要特征被抑制）。
> 
> 通俗来讲：  SE模块就像个智能调音台：它先把每个“声音通道”（特征图通道）的整体响度汇总起来（Squeeze）， 然后让神经网络自动判断哪个通道最重要并给它们分配一个音量大小（0-1，Excitation）， 最后用这个音量大小去放大重要的通道、减弱不重要的通道（Scale），让网络更专注于关键信息。

**2.整体架构：**
EfficientNet-B4 由一系列阶段（Stage）组成，每个阶段包含若干个相同的 MBConv 块（数量由缩放系数 φ 决定）。不同阶段的主要变化：
- 输入分辨率：随着网络加深逐渐降低（通过 stride=2 的卷积或池化）。
- 通道数： 随着网络加深逐渐增加（通过 1x1 Conv 或第一个 MBConv 的投影层）。
- MBConv 类型： 早期层可能使用较小的核（如 3x3）和较小的扩展比（如 4），后期层可能使用较大的核（如 5x5）和较大的扩展比（如 6）。具体配置在基线模型 B0 中由 NAS 搜索确定，B4 继承了这些配置并应用了缩放。

**EfficientNet-B4 关键参数与性能 (典型值，基于 ImageNet 数据集)**

- 输入分辨率：380x380(这是区分 B0-B7 的重要标志之一)
- 宽度系数 (Width Multiplier w): ≈ 1.2 (相对于 B0)
- 深度系数 (Depth Multiplier d): ≈ 1.3 (相对于 B0)
- 参数数量 (Params)： ≈ 19.3 Million (19.3M)
- 浮点运算量 (FLOPs)： ≈ 4.2 Billion (4.2G)
- ImageNet Top-1 Accuracy： ≈ 82.9% - 83.3% (具体数值可能因训练细节、数据增强、正则化策略等略有差异)
- ImageNet Top-5 Accuracy： ≈ 96.3% - 96.5%

**主要应用场景**

- 图像分类 (Image Classification)： 最直接的应用，作为基础模型。
- 目标检测 (Object Detection)： 作为骨干网络（如与 RetinaNet, Faster R-CNN, YOLO 等检测头结合），在 COCO 等数据集上取得 SOTA 效率。
- 语义分割 (Semantic Segmentation)： 作为骨干网络（如与 U-Net, DeepLabV3+ 等分割头结合），在 Cityscapes, ADE20K 等数据集上高效运行。
- 迁移学习 (Transfer Learning)： 在 ImageNet 上预训练的 EfficientNet-B4 是极佳的预训练模型，可迁移到各种自定义的、数据量较小的视觉任务中（如医学影像分析、卫星图像识别、工业质检），通常只需微调即可获得优异性能。
- 特征提取 (Feature Extraction)： 提取图像的高层语义特征用于其他任务（如图像检索、内容理解）。

**总结**
<p style="text-indent: 2em;">
EfficientNet-B4 是 EfficientNet 家族中一个性能与效率平衡得非常出色的中型模型。它通过创新的复合缩放策略（协调缩放深度、宽度、分辨率）和高效的MBConv with SE 基础块，在约 19M 参数和 4.2G FLOPs 的计算成本下，实现了接近 83% 的 ImageNet Top-1 精度，显著超越了同等计算成本的传统模型。它非常适合作为各种计算机视觉任务（分类、检测、分割）的骨干网络，尤其在需要较高精度但对模型大小和计算速度也有一定要求的场景（如云端推理、高端移动端应用、作为强大的预训练模型）。理解其核心的复合缩放思想和 MBConv-SE 结构是掌握 EfficientNet-B4 的关键。使用时务必注意其对训练技巧的依赖性和输入分辨率的要求。
</p>